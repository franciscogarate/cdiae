{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franciscogarate/cdiae/blob/main/notebooks/2_Transformaciones_basicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9226fdf",
      "metadata": {
        "id": "e9226fdf"
      },
      "source": [
        "# Proceso completo de Extracción, Transformación y Carga\n",
        "Partimos del fichero con datos en bruto llamado **empleados_metacortex.csv**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/franciscogarate/cdiae"
      ],
      "metadata": {
        "id": "aExnto73fC-V"
      },
      "id": "aExnto73fC-V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c9fafd1",
      "metadata": {
        "id": "9c9fafd1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file = 'cdiae/data/01_raw/empleados_metacortex.csv'\n",
        "df = pd.read_csv(\n",
        "        file,\n",
        "        sep=';',                    # Separador de campos\n",
        "        header=3,                   # Fila 4 contiene los encabezados (0-indexed, salta comentarios)\n",
        "        encoding='utf-8',           # Codificación de caracteres\n",
        "        skipfooter=1,               # Omite la última 1 fila (comentarios finales)\n",
        "        engine='python',            # Necesario para skipfooter\n",
        "        comment='%',                # Líneas que empiecen con % son comentarios\n",
        "        usecols=['fecha_nacimiento','fecha_alta','nombre','sexo_biologico','nif','codigo_postal','genero','departamento','activo','horas_semanales','bonus'],\n",
        "        parse_dates=['fecha_nacimiento', 'fecha_alta'],  # Convierte automáticamente a datetime\n",
        "        date_format='%Y-%m-%d',      # OJO: Formato único para todas las columnas de fecha\n",
        "        na_values=['', 'N/A', 'null', 'NULL'],\n",
        "        keep_default_na=True,\n",
        ")\n",
        "df['fecha_alta'] = pd.to_datetime(df['fecha_alta'], format='%Y/%m/%d')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ebb2072",
      "metadata": {
        "id": "1ebb2072"
      },
      "source": [
        "### Cruce de datos con otros ficheros\n",
        "Partiendo de nuestros datos, vamos a complementarlos con información externa como los pagos efectuados que residen en un fichero de Excel externo.\n",
        "Para ello utilizaremos las siguientes funciones de pandas:\n",
        "  - `DataFrame.groupby`\n",
        "  - `DataFrame.reset_index`\n",
        "  - `pd.merge`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a36f6aa1",
      "metadata": {
        "id": "a36f6aa1"
      },
      "source": [
        "Lectura del Excel con pagos de empleados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d29c41",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "e7d29c41"
      },
      "outputs": [],
      "source": [
        "df_pagos = pd.read_excel('cdiae/data/01_raw/pagos_empleados_metacortex.xlsx')\n",
        "df_pagos.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67941272",
      "metadata": {
        "id": "67941272"
      },
      "source": [
        "Renombramos columnas para coincidir con el nombre de las columnas de 'df' antes del cruce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bd4951a",
      "metadata": {
        "id": "5bd4951a"
      },
      "outputs": [],
      "source": [
        "df_pagos.rename(columns={'NIF': 'nif', 'IMPORTE': 'pago'}, inplace=True)\n",
        "df_pagos.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pagos.nif.value_counts()"
      ],
      "metadata": {
        "id": "pDwzRnnGM4hm"
      },
      "id": "pDwzRnnGM4hm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ab0a44ad",
      "metadata": {
        "id": "ab0a44ad"
      },
      "source": [
        "Inspeccionamos los datos por su tipo, aquellos nulos y la memoria del DataFrame de pagos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904fc90d",
      "metadata": {
        "id": "904fc90d"
      },
      "outputs": [],
      "source": [
        "df_pagos.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bb425fc",
      "metadata": {
        "id": "1bb425fc"
      },
      "source": [
        "Agregamos pagos por empleado (nif) sumando todos sus registros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412cb23b",
      "metadata": {
        "id": "412cb23b"
      },
      "outputs": [],
      "source": [
        "df_pagos_agg = df_pagos.groupby('nif')['pago'].sum().reset_index()\n",
        "df_pagos_agg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f669ced1",
      "metadata": {
        "id": "f669ced1"
      },
      "source": [
        "Hacemos un left join para añadir 'pago' al DataFrame principal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8234f981",
      "metadata": {
        "id": "8234f981"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(df, df_pagos_agg, on=['nif'], how='left')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e370cc13",
      "metadata": {
        "id": "e370cc13"
      },
      "source": [
        "## Distintos procesos de transformación de datos\n",
        "### Map y replace\n",
        "Unas de las funciones que podemos utilizar para reemplazar y unificar los valores posibles son `map` y `replace`.\n",
        "Adicionalmente, para poder todos los valores que posee un campo podemos usar las funciones `unique` y `nunique`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89600363",
      "metadata": {
        "id": "89600363"
      },
      "outputs": [],
      "source": [
        "df.sexo_biologico.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "743c4db6",
      "metadata": {
        "id": "743c4db6"
      },
      "source": [
        "Valores únicos de la columna 'genero' antes del mapeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c655c30",
      "metadata": {
        "id": "2c655c30"
      },
      "outputs": [],
      "source": [
        "df.genero.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59631636",
      "metadata": {
        "id": "59631636"
      },
      "source": [
        "Homogeneizamos etiquetas: 'Mujer'->'F' y 'Hombre'->'M'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85a3a4f",
      "metadata": {
        "id": "f85a3a4f"
      },
      "outputs": [],
      "source": [
        "df['genero'] = df['genero'].map({'Mujer':'F', 'Hombre':'M'})\n",
        "df.genero.unique()                                                  # Valores únicos tras el mapeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97937f29",
      "metadata": {
        "id": "97937f29"
      },
      "outputs": [],
      "source": [
        "df.activo.unique()                                                  # Valores únicos actuales de 'activo'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd7d822",
      "metadata": {
        "id": "2cd7d822"
      },
      "source": [
        "### Reemplazar con un condicional"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bcd3d7",
      "metadata": {
        "id": "54bcd3d7"
      },
      "source": [
        "Ejemplo de conversión con apply (mantener comentado si no se necesita)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc104cc2",
      "metadata": {
        "id": "cc104cc2"
      },
      "outputs": [],
      "source": [
        "df['activo'] = df.apply(lambda x: True if x.activo == 'Sí' else False, axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697db731",
      "metadata": {
        "id": "697db731"
      },
      "source": [
        "Resumen de tipos de datos y memoria tras las transformaciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e879be",
      "metadata": {
        "id": "90e879be"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2644e16d",
      "metadata": {
        "id": "2644e16d"
      },
      "source": [
        "## Guardado de datos\n",
        "- El último paso del proceso de ETL es la carga o guardado (loading). Para ello, no vamos a utilizar el mismo formato del fichero origen (raw) sino que dicho fichero transformado, siguiendo los estandares de buenas prácticas, vamos a guardarlo como ficheros intermedios en un formato que incorporé el formato.\n",
        "- La mejor opción para ficheros intermedios son los formatos feather y parquet.\n",
        "- Veamos las principales caracteristicas, así como pros y contras de cada uno de ellos.\n",
        "### Feather\n",
        "El formato Feather es un formato de archivo binario para almacenar datos de forma eficiente. Es un formato abierto y ligero que se utiliza para el intercambio de datos entre aplicaciones y lenguajes de programación.\n",
        "Así, es el lenguage ideal para guardar nuestras base de datos _intermedias_ en nuestro flujo de transformaciones en python, así como para compartir dichos ficheros con otros programas escritos en R, ya que R tambien lee sin problemas el formato Feather.\n",
        "### Parquet\n",
        "El formato Parquet, en cambio, es un formato de archivo columnar (en columnas) muy eficiente que se utiliza para almacenar datos principalmente de texto. Tambien es un formato abierto y ligero que se utiliza para el intercambio de datos entre aplicaciones y lenguajes de programación.\n",
        "- Ambos tienen compatibilidad con pandas, pero Parquet es más eficiente para grandes volúmenes de datos.\n",
        "    - `df.to_parquet('ruta/archivo.parquet')`\n",
        "    - `df.to_feather('ruta/archivo.feather')`\n",
        "- Feather y Parquet mantienen los tipos de datos originales (int64, float64, datetime, etc.), a diferencia de CSV que convierte todo a texto.\n",
        "- Las principales diferencias son:\n",
        "    - Feather está diseñado específicamente para ser extremadamente rápido en lectura/escritura\n",
        "    - Feather usa un formato binario sencillo basado en Apache Arrow, lo que lo hace ideal para intercambio rápido entre Python y R.\n",
        "    - Parquet utiliza una compresión mas compleja pensada en reducir el tamaño\n",
        "    - Feather tiene menor compresión que Parquet, resultando en archivos más grandes, pero con acceso más rápido.\n",
        "- Existe tambien el formato pickle aunque es especifico para python\n",
        "- Mi recomendación para ficheros temporales de cualquier tamaño es Feather, y Parquet para ficheros muy pesados que vayan a almacenarse en la nube (> 10 GB) o dataset con muchas columnas, ya que en estos casos, Parquet puede llegar a comprimir hasta 10 veces.\n",
        "- Cuando trabajas con fichero .parquet no puedes importar las x primeras lineas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581d5490",
      "metadata": {
        "id": "581d5490"
      },
      "outputs": [],
      "source": [
        "df.to_feather('cdiae/data/02_intermediate/empleados_metacortex.ftr')   # Guardamos el dataset intermedio en formato Feather"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "paco",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}